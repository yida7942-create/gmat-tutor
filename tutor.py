"""
GMAT Focus AI Tutor - AI Tutor Layer
Handles LLM interactions for explanations and summaries.
"""

import os
from typing import Optional, Dict, List
from dataclasses import dataclass
from database import Question, StudyLog

# ============== Configuration ==============

@dataclass
class TutorConfig:
    """Configuration for AI tutor.
    
    Supports OpenAI-compatible APIs (ç«å±±æ–¹èˆŸ, DeepSeek, Moonshot, etc.)
    by setting base_url to the provider's endpoint.
    
    Examples:
        ç«å±±æ–¹èˆŸ: base_url="https://ark.cn-beijing.volces.com/api/v3"
        DeepSeek: base_url="https://api.deepseek.com"
        Moonshot: base_url="https://api.moonshot.cn/v1"
        OpenAI:   base_url=None (uses default)
    """
    model: str = "gpt-4o-mini"  # Default model; set to your endpoint ID for ç«å±±æ–¹èˆŸ
    base_url: str = None  # Set to provider's API endpoint URL
    max_tokens: int = 1500
    temperature: float = 0.7


# ============== Prompt Templates ==============

SYSTEM_PROMPT = """You are a GMAT expert tutor who has helped thousands of students achieve 99th percentile scores. 

Your teaching style:
- Patient and encouraging, but rigorous
- Focus on building fundamental reasoning skills
- Use clear, structured explanations
- Help students recognize patterns and traps

Language: Always respond in the same language as the user's question or the language they prefer. If the question is in Chinese, respond in Chinese. If in English, respond in English."""


EXPLANATION_PROMPT_TEMPLATE = """A student answered a GMAT {question_type} question. Provide a comprehensive analysis of ALL options.

**Question Type:** {question_type}
**Question:**
{question_content}

**Options:**
A. {option_a}
B. {option_b}
C. {option_c}
D. {option_d}
E. {option_e}

**Correct Answer:** {correct_answer}
**Student Selected:** {student_answer}
**Student was correct:** {is_correct}
**Question Tags:** {skill_tags}

### ðŸ’¡ æ ¸å¿ƒæ€è·¯ (Key Insight)
In 1-2 sentences, identify the core logical gap, pattern, or testing point.
**Must include "é€»è¾‘é“¾æž„å»º" (Logic Chain):** 1. Premise -> 2. Conflict/Goal -> 3. Prediction.

### ðŸ” é€‰é¡¹æ·±åº¦è¾¨æž (Comprehensive Option Analysis)
Analyze ALL options (A-E).
*   **For the Student's Error ({student_answer})**: Analyze why this specific trap is tempting but wrong. What logical flaw does it commit?
*   **For the Correct Answer ({correct_answer})**: Explain the direct logical chain. How does it perfectly address the gap?
*   **For Other Options**: Briefly explain why they are incorrect.

**Format:**
*   **A**: [Analysis]
*   **B**: [Analysis]
...

### ðŸ”‘ ä¸€å¥è¯è®°ä½
One actionable takeaway sentence.

**Example Output:**
### ðŸ’¡ æ ¸å¿ƒæ€è·¯ (Key Insight)
**é€»è¾‘é“¾æž„å»º**ï¼š
1.  **å‰æ**ï¼šåŽ»æžèƒ½å‡å°‘é‡é‡ï¼ˆå¯èƒ½é™ä½Žè¿è´¹ï¼‰ã€‚
2.  **å†²çª**ï¼šåŽ»æžè¿™ä¸€åŠ¨ä½œæœ¬èº«éœ€è¦æˆæœ¬ã€‚
3.  **æ ¸å¿ƒé—®é¢˜**ï¼šä¸ºäº†è¯æ˜Ž"åŽ»æžæ›´åˆ’ç®—"ï¼Œå¿…é¡»ä¿è¯"çœä¸‹çš„è¿è´¹ > å¢žåŠ çš„åŽ»æžæˆæœ¬"ã€‚
4.  **è§£é¢˜æ–¹å‘**ï¼šå¯»æ‰¾èƒ½æ”¾å¤§"è¿è´¹èŠ‚çœ"æˆ–ç¼©å°"åŽ»æžæˆæœ¬"çš„å…³é”®å˜é‡ã€‚
*æœ¬é¢˜è€ƒç‚¹ï¼šæ–¹æ¡ˆå¯è¡Œæ€§è¯„ä¼°*

### ðŸ” é€‰é¡¹æ·±åº¦è¾¨æž (Comprehensive Option Analysis)
*   **A**: [æ— å…³] ...
*   âŒ **B (ä½ çš„é€‰æ‹©)**: [æ··æ·†ç»“è®ºä¸Žè®ºæ®] â€œåœ¨å·¥åŽ‚åŽ»æžä¼šæ›´ç»æµŽã€‚â€ è¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªæ”¯æŒæ–¹æ¡ˆçš„ç†ç”±ï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªæœªç»è¯å®žçš„å‡è®¾ç»“è®º...
*   âœ… **D (æ­£ç¡®ç­”æ¡ˆ)**: [å¡«è¡¥ Gap] **â€œè¿è¾“æˆæœ¬ç”±ä½“ç§¯å†³å®šï¼Œè€Œéžé‡é‡ã€‚â€** æ—¢ç„¶åŽ»æžåŽçš„æœ¨ç‰‡ä½“ç§¯åªæœ‰æ ‘æžçš„ä¸€åŠ...
...

### ðŸ”‘ ä¸€å¥è¯è®°ä½
é‡åˆ°[è¯„ä¼°æ–¹æ¡ˆå¯è¡Œæ€§]æ—¶ï¼Œè¦å…³æ³¨æ–¹æ¡ˆå¸¦æ¥çš„æ ¸å¿ƒå˜åŒ–ï¼ˆå¦‚æˆæœ¬ç»“æž„çš„å˜åŒ–ï¼‰ã€‚

**IMPORTANT:** Please respond in **Chinese** (except for specific English terms). Keep logic analysis sharp and direct."""


SUMMARY_PROMPT_TEMPLATE = """åŸºäºŽä»Šå¤©çš„å­¦ä¹ è®°å½•ï¼Œè¯·ç”Ÿæˆä¸€ä»½ç®€è¦çš„ä¸­æ–‡å­¦ä¹ æ€»ç»“å’Œå»ºè®®ã€‚

**å­¦ä¹ æ•°æ®:**
- å®Œæˆé¢˜ç›®: {total_questions}
- æ­£ç¡®æ•°é‡: {correct_count}
- æ­£ç¡®çŽ‡: {accuracy}%
- å¹³å‡ç”¨æ—¶: {avg_time} ç§’/é¢˜

**é”™è¯¯ç±»åž‹åˆ†å¸ƒ:**
{error_breakdown}

**è–„å¼±è€ƒç‚¹:**
{weak_tags}

è¯·è¾“å‡ºä»¥ä¸‹å†…å®¹ï¼ˆå…¨éƒ¨ç”¨ä¸­æ–‡ï¼‰:
1. **ä»Šæ—¥ç‚¹è¯„**: å¯¹ä»Šå¤©è¡¨çŽ°çš„ç®€è¦è¯„ä¼° (2-3å¥è¯)
2. **äº®ç‚¹**: è¡¨çŽ°å¥½çš„åœ°æ–¹
3. **æå‡ç©ºé—´**: éœ€è¦é‡ç‚¹æ”¹è¿›çš„é¢†åŸŸ
4. **æ˜Žæ—¥å»ºè®®**: å¯¹æŽ¥ä¸‹æ¥ç»ƒä¹ çš„å…·ä½“å»ºè®®

è¯­æ°”è¦ç§¯æžé¼“åŠ±ä½†å®žäº‹æ±‚æ˜¯ã€‚ä¿æŒç®€æ´æ‰¼è¦ã€‚"""




LANGUAGE_HELP_PROMPT_TEMPLATE = """Analyze the language aspects of this GMAT {question_type} question.

**Question Content:**
{question_content}

Please provide:

### ðŸ§¬ é•¿éš¾å¥ç²¾è®² (Sentence Analysis)
Select the 1-2 most complex sentences from the text.
*   **åŽŸå¥**: [English Sentence]
*   **ç»“æž„**: [Analyze the structure]
*   **ç²¾è¯‘**: [Chinese Translation]
*   **ç‚¹æ‹¨**: [Grammar point]

### ðŸ“ æ ¸å¿ƒè¯æ±‡ (Core Vocabulary)
List 3-5 critical words/phrases.
*   **Word/Phrase** â€” ä¸­æ–‡é‡Šä¹‰ â€” Contextual usage notes.

**Example:**
### ðŸ§¬ é•¿éš¾å¥ç²¾è®² (Sentence Analysis)
*   **åŽŸå¥**: Although the discount stores in Gorevilleâ€™s central shopping district are expected to close...
*   **ç»“æž„**: `Although` [subsidiary clause] ..., `main clause` ...
*   **ç²¾è¯‘**: å°½ç®¡å„å°”ç»´å°”ä¸­å¿ƒå•†ä¸šåŒºçš„æŠ˜æ‰£åº—é¢„è®¡å°†åœ¨äº”å¹´å†…å€’é—­...
*   **ç‚¹æ‹¨**: æ³¨æ„ `as a result of` å¼•å¯¼çš„åŽŸå› çŠ¶è¯­...

**IMPORTANT:** Please respond in **Chinese**."""

QUICK_TIP_PROMPT_TEMPLATE = """For a GMAT {question_type} question testing "{skill_tag}", give ONE quick tip (2-3 sentences max) that helps identify the correct answer pattern."""

TRANSLATION_PROMPT_TEMPLATE = """Provide a bilingual translation and analysis for this GMAT question.

**Context/Argument:**
{question_content}

**Options:**
A. {option_a}
B. {option_b}
C. {option_c}
D. {option_d}
E. {option_e}

Please follow this output format strictly. Use Clear Styling (Bold English / Plain Chinese). No blockquotes.

### ðŸŒ ä¸­è‹±å¯¹ç…§ç¿»è¯‘
(Break down the argument/passage by sentence or logical chunk.)

**"English Sentence 1"**
ä¸­æ–‡ç¿»è¯‘ 1

**"English Sentence 2"**
ä¸­æ–‡ç¿»è¯‘ 2

**(Continue for the whole passage...)**

### é€‰é¡¹ç¿»è¯‘ (ä¸­è‹±å¯¹ç…§)

- **A**:
    **"English Option Content"**
    ä¸­æ–‡ç¿»è¯‘å†…å®¹
- **B**:
    **"English Option Content"**
    ä¸­æ–‡ç¿»è¯‘å†…å®¹
...

(End of translation)
"""




# ============== AI Tutor ==============

class AITutor:
    """AI-powered tutor using LLM for explanations."""
    
    def __init__(self, config: TutorConfig = None, api_key: str = None, base_url: str = None):
        self.config = config or TutorConfig()
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY") or os.environ.get("ARK_API_KEY")
        # Allow base_url from parameter, config, or env
        self.base_url = base_url or self.config.base_url or os.environ.get("OPENAI_BASE_URL")
        self._client = None
    
    def _get_client(self):
        """Lazy initialization of OpenAI-compatible client."""
        if self._client is None:
            if not self.api_key:
                return None
            try:
                from openai import OpenAI
                kwargs = {"api_key": self.api_key}
                if self.base_url:
                    kwargs["base_url"] = self.base_url
                self._client = OpenAI(**kwargs)
            except ImportError:
                print("Warning: openai package not installed. AI features disabled.")
                return None
        return self._client
    
    def is_available(self) -> bool:
        """Check if AI features are available."""
        return self._get_client() is not None
    
    def explain_failure(self, 
                       question: Question, 
                       user_answer: int,
                       is_correct: bool = False,
                       language: str = "zh") -> str:
        """
        Generate a detailed explanation focusing on why the user's choice was wrong.
        
        Args:
            question: The question object
            user_answer: Index of the user's selected answer (0-4)
            is_correct: Whether the user answered correctly
            language: "zh" for Chinese, "en" for English
        
        Returns:
            Explanation text
        """
        client = self._get_client()
        
        # Format the prompt
        option_letters = ['A', 'B', 'C', 'D', 'E']
        question_type = "Reading Comprehension (RC)" if question.subcategory == "RC" else "Critical Reasoning (CR)"
        prompt = EXPLANATION_PROMPT_TEMPLATE.format(
            question_type=question_type,
            question_content=question.content,
            option_a=question.options[0],
            option_b=question.options[1],
            option_c=question.options[2],
            option_d=question.options[3],
            option_e=question.options[4],
            correct_answer=option_letters[question.correct_answer],
            student_answer=option_letters[user_answer],
            is_correct="Yes" if is_correct else "No",
            skill_tags=", ".join(question.skill_tags)
        )
        
        if not client:
            # Fallback to stored explanation if available
            return self._fallback_explanation(question, user_answer)
        
        return self._call_llm(prompt, fallback_func=lambda e: self._fallback_explanation(question, user_answer) + f"\n\n> âš ï¸ **API è°ƒç”¨é”™è¯¯**: {str(e)}\n> è¯·æ£€æŸ¥ Settings é¡µé¢ä¸­çš„ API Key å’Œé…ç½®æ˜¯å¦æ­£ç¡®ã€‚")
    
    def _fallback_explanation(self, question: Question, user_answer: int) -> str:
        """Provide a basic explanation when AI is not available."""
        option_letters = ['A', 'B', 'C', 'D', 'E']
        
        explanation = f"""## ç­”æ¡ˆè§£æž

**æ­£ç¡®ç­”æ¡ˆï¼š** {option_letters[question.correct_answer]}
**ä½ çš„é€‰æ‹©ï¼š** {option_letters[user_answer]}

"""
        if question.explanation:
            explanation += f"**è§£æžï¼š** {question.explanation}\n\n"
        
        explanation += f"**è€ƒç‚¹æ ‡ç­¾ï¼š** {', '.join(question.skill_tags)}\n\n"
        explanation += "_æç¤ºï¼šé…ç½® API Key åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„ AI è®²è§£ã€‚_"
        
        return explanation

    def analyze_language(self, question: Question) -> str:
        """
        Generate language analysis (sentence structure & vocabulary).
        """
        question_type = "Reading Comprehension (RC)" if question.subcategory == "RC" else "Critical Reasoning (CR)"
        prompt = LANGUAGE_HELP_PROMPT_TEMPLATE.format(
            question_type=question_type,
            question_content=question.content
        )
        return self._call_llm(prompt)

    def translate_question(self, question: Question) -> str:
        """Translate question content to Chinese."""
        prompt = TRANSLATION_PROMPT_TEMPLATE.format(
            question_content=question.content,
            option_a=question.options[0],
            option_b=question.options[1],
            option_c=question.options[2],
            option_d=question.options[3],
            option_e=question.options[4]
        )
        return self._call_llm(prompt, system_prompt="You are a professional GMAT tutor and translator.", temperature=0.3)

    def _call_llm(self, prompt: str, system_prompt: str = SYSTEM_PROMPT, max_tokens: int = None, temperature: float = None, fallback_func=None) -> str:
        """Helper to call LLM API."""
        client = self._get_client()
        if not client:
            return "âš ï¸ AI æœªè¿žæŽ¥ï¼Œè¯·é…ç½® API Keyã€‚"
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens if max_tokens is not None else self.config.max_tokens,
                temperature=temperature if temperature is not None else self.config.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            if fallback_func:
                return fallback_func(e)
            return f"âŒ AI ç”Ÿæˆå¤±è´¥: {str(e)}"



    def generate_session_summary(self,
                                logs: List[StudyLog],
                                questions: Dict[int, Question]) -> str:
        """
        Generate a summary of a study session.
        
        Args:
            logs: List of study logs from the session
            questions: Dict mapping question_id to Question objects
        """
        if not logs:
            return "æ²¡æœ‰å­¦ä¹ è®°å½•å¯ä¾›æ€»ç»“ã€‚"
        
        # Calculate statistics
        total = len(logs)
        correct = sum(1 for log in logs if log.is_correct)
        accuracy = (correct / total * 100) if total > 0 else 0
        avg_time = sum(log.time_taken for log in logs) / total if total > 0 else 0
        
        # Error breakdown
        error_counts = {}
        tag_errors = {}
        
        for log in logs:
            if not log.is_correct:
                # Count by error category
                cat = log.error_category or "Unspecified"
                error_counts[cat] = error_counts.get(cat, 0) + 1
                
                # Count by skill tag
                q = questions.get(log.question_id)
                if q:
                    for tag in q.skill_tags:
                        tag_errors[tag] = tag_errors.get(tag, 0) + 1
        
        error_breakdown = "\n".join(f"- {cat}: {count}" for cat, count in error_counts.items()) or "- None"
        
        weak_tags = sorted(tag_errors.items(), key=lambda x: x[1], reverse=True)[:3]
        weak_tags_str = "\n".join(f"- {tag}: {count} errors" for tag, count in weak_tags) or "- None"
        
        prompt = SUMMARY_PROMPT_TEMPLATE.format(
            total_questions=total,
            correct_count=correct,
            accuracy=f"{accuracy:.1f}",
            avg_time=f"{avg_time:.0f}",
            error_breakdown=error_breakdown,
            weak_tags=weak_tags_str
        )
        
        client = self._get_client()
        if not client:
            return self._fallback_summary(total, correct, accuracy, avg_time, weak_tags)
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"AI summary error: {e}")
            return self._fallback_summary(total, correct, accuracy, avg_time, weak_tags)
    
    def _fallback_summary(self, total: int, correct: int, accuracy: float, 
                         avg_time: float, weak_tags: List[tuple]) -> str:
        """Generate a basic summary when AI is not available."""
        summary = f"""## ä»Šæ—¥å­¦ä¹ æ€»ç»“

**ç»ƒä¹ æ•°æ®ï¼š**
- å®Œæˆé¢˜ç›®ï¼š{total} é¢˜
- æ­£ç¡®æ•°é‡ï¼š{correct} é¢˜
- æ­£ç¡®çŽ‡ï¼š{accuracy:.1f}%
- å¹³å‡ç”¨æ—¶ï¼š{avg_time:.0f} ç§’/é¢˜

"""
        if weak_tags:
            summary += "**è–„å¼±çŽ¯èŠ‚ï¼š**\n"
            for tag, count in weak_tags:
                summary += f"- {tag}: {count} é“é¢˜åšé”™\n"
            summary += "\n"
        
        if accuracy >= 80:
            summary += "âœ… **æ•´ä½“è¡¨çŽ°è‰¯å¥½ï¼** ç»§ç»­ä¿æŒå½“å‰çš„å­¦ä¹ èŠ‚å¥ã€‚\n"
        elif accuracy >= 60:
            summary += "ðŸ“ˆ **è¡¨çŽ°ä¸­ç­‰ã€‚** å»ºè®®é’ˆå¯¹è–„å¼±çŽ¯èŠ‚è¿›è¡Œä¸“é¡¹è®­ç»ƒã€‚\n"
        else:
            summary += "âš ï¸ **éœ€è¦åŠ å¼ºåŸºç¡€ã€‚** å»ºè®®æ”¾æ…¢é€Ÿåº¦ï¼Œä»”ç»†åˆ†æžæ¯é“é”™é¢˜ã€‚\n"
        
        summary += "\n_æç¤ºï¼šé…ç½® API Key åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„ AI åˆ†æžå’Œä¸ªæ€§åŒ–å»ºè®®ã€‚_"
        
        return summary
    
    def get_quick_tip(self, question_type: str, skill_tag: str) -> str:
        """Get a quick tip for a specific question type and skill."""
        client = self._get_client()
        
        prompt = QUICK_TIP_PROMPT_TEMPLATE.format(
            question_type=question_type,
            skill_tag=skill_tag
        )
        
        if not client:
            return self._get_fallback_tip(skill_tag)
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return self._get_fallback_tip(skill_tag)
    
    def _get_fallback_tip(self, skill_tag: str) -> str:
        """Provide a static tip based on skill tag."""
        tips = {
            "Assumption": "æ‰¾å‡è®¾é¢˜çš„å…³é”®ï¼šæ­£ç¡®ç­”æ¡ˆæ˜¯è®ºè¯æˆç«‹çš„å¿…è¦æ¡ä»¶ã€‚ç”¨'å¦å®šæµ‹è¯•'â€”â€”å¦‚æžœå¦å®šæŸä¸ªé€‰é¡¹åŽè®ºè¯å´©å¡Œï¼Œé‚£å°±æ˜¯æ­£ç¡®ç­”æ¡ˆã€‚",
            "Strengthen": "åŠ å¼ºé¢˜è¦æ‰¾èƒ½å¡«è¡¥è®ºè¯ç¼ºå£çš„é€‰é¡¹ã€‚æ³¨æ„ï¼šå¥½çš„åŠ å¼ºé€‰é¡¹ä¸éœ€è¦'è¯æ˜Ž'ç»“è®ºï¼Œåªéœ€è¦è®©ç»“è®º'æ›´å¯èƒ½'æˆç«‹ã€‚",
            "Weaken": "å‰Šå¼±é¢˜è¦æ”»å‡»'å‰æåˆ°ç»“è®º'çš„æŽ¨ç†è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯æ”»å‡»å‰ææœ¬èº«ã€‚å¯»æ‰¾æ›¿ä»£è§£é‡Šæˆ–ç ´åå› æžœé“¾çš„é€‰é¡¹ã€‚",
            "Inference": "æŽ¨æ–­é¢˜è¦æ±‚'å¿…ç„¶ä¸ºçœŸ'ã€‚å°å¿ƒ'å¤§å¤šæ•°'â‰ 'æ‰€æœ‰'ï¼Œ'æœ‰äº›'â‰ 'å¿…ç„¶'ã€‚æ­£ç¡®é€‰é¡¹é€šå¸¸æ¯”ä½ é¢„æœŸçš„æ›´ä¿å®ˆã€‚",
            "Evaluate": "è¯„ä¼°é¢˜è¦æ‰¾èƒ½å†³å®šè®ºè¯å¼ºå¼±çš„å…³é”®ä¿¡æ¯ã€‚é—®è‡ªå·±ï¼š'å¦‚æžœçŸ¥é“è¿™ä¸ªä¿¡æ¯ï¼Œç»“è®ºä¼šæ›´å¼ºè¿˜æ˜¯æ›´å¼±ï¼Ÿ'",
            "Boldface": "ç²—ä½“é¢˜å…ˆåˆ¤æ–­æ¯ä¸ªç²—ä½“éƒ¨åˆ†çš„è§’è‰²ï¼ˆç»“è®ºï¼Ÿå‰æï¼Ÿåé©³ï¼Ÿï¼‰ï¼Œå†çœ‹å®ƒä»¬ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚"
        }
        return tips.get(skill_tag, "ä»”ç»†é˜…è¯»é¢˜å¹²ï¼Œè¯†åˆ«è®ºè¯ç»“æž„ï¼Œæ³¨æ„é¢˜ç›®é—®çš„æ˜¯ä»€ä¹ˆã€‚")


# ============== Error Taxonomy Reference ==============

ERROR_TAXONOMY = {
    "Understanding": {
        "description": "ç†è§£å±‚é¢çš„é”™è¯¯ - æ²¡æœ‰æ­£ç¡®ç†è§£é¢˜ç›®æˆ–é€‰é¡¹çš„å«ä¹‰",
        "types": {
            "Text Misinterpretation": "è¯¯è§£é¢˜å¹²ä¸­çš„å…³é”®ä¿¡æ¯æˆ–è®ºè¯ç»“æž„",
            "Option Misinterpretation": "è¯¯è§£é€‰é¡¹çš„å®žé™…å«ä¹‰"
        },
        "remedy": "æ”¾æ…¢é˜…è¯»é€Ÿåº¦ï¼Œç”¨è‡ªå·±çš„è¯å¤è¿°è®ºè¯"
    },
    "Reasoning": {
        "description": "æŽ¨ç†å±‚é¢çš„é”™è¯¯ - ç†è§£äº†ä½†æŽ¨ç†è¿‡ç¨‹å‡ºé”™",
        "types": {
            "Confusion (Suff/Nec)": "æ··æ·†å……åˆ†æ¡ä»¶å’Œå¿…è¦æ¡ä»¶",
            "Reverse Causality": "é¢ å€’å› æžœå…³ç³»",
            "Scope Shift": "èŒƒå›´è½¬ç§» - é€‰é¡¹è®¨è®ºçš„èŒƒå›´ä¸Žé¢˜å¹²ä¸ä¸€è‡´",
            "Trap Answer": "æŽ‰å…¥å¸¸è§é™·é˜±é€‰é¡¹"
        },
        "remedy": "ç»ƒä¹ è¯†åˆ«è®ºè¯æ¨¡å¼ï¼Œå­¦ä¹ å¸¸è§é™·é˜±ç±»åž‹"
    },
    "Execution": {
        "description": "æ‰§è¡Œå±‚é¢çš„é”™è¯¯ - ä¼šåšä½†åšé”™äº†",
        "types": {
            "Time Pressure": "æ—¶é—´åŽ‹åŠ›å¯¼è‡´ä»“ä¿ƒç­”é¢˜",
            "Careless": "ç²—å¿ƒå¤§æ„ï¼Œæ¼çœ‹å…³é”®è¯"
        },
        "remedy": "ç»ƒä¹ æ—¶é—´ç®¡ç†ï¼Œå»ºç«‹æ£€æŸ¥ä¹ æƒ¯"
    }
}


def get_error_taxonomy() -> Dict:
    """Return the error taxonomy for UI display."""
    return ERROR_TAXONOMY


# ============== Test ==============

def test_tutor():
    """Test the AI tutor with a sample question."""
    print("\n=== Testing AI Tutor ===\n")
    
    tutor = AITutor()
    
    print(f"AI Available: {tutor.is_available()}")
    
    # Create a sample question
    sample_q = Question(
        id=1,
        passage_id=None,
        category="Verbal",
        subcategory="CR",
        content="Studies show that employees who work from home report higher job satisfaction. Therefore, all companies should mandate remote work.",
        options=[
            "Working from home is possible for all jobs",
            "Job satisfaction improves productivity",
            "Remote workers are more loyal",
            "Office rent is expensive",
            "Commuting is stressful"
        ],
        correct_answer=0,
        skill_tags=["Assumption"],
        difficulty=3,
        explanation="The argument assumes all jobs can be done remotely."
    )
    
    print("Testing explanation generation...")
    explanation = tutor.explain_failure(sample_q, user_answer=1)
    print(explanation[:500] + "..." if len(explanation) > 500 else explanation)
    
    print("\nâœ“ Tutor test complete!")


if __name__ == "__main__":
    test_tutor()
