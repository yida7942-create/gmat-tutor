"""
GMAT Focus AI Tutor - AI Tutor Layer
Handles LLM interactions for explanations and summaries.
"""

import os
from typing import Optional, Dict, List
from dataclasses import dataclass
from database import Question, StudyLog

# ============== Configuration ==============

@dataclass
class TutorConfig:
    """Configuration for AI tutor.
    
    Supports OpenAI-compatible APIs (ç«å±±æ–¹èˆŸ, DeepSeek, Moonshot, etc.)
    by setting base_url to the provider's endpoint.
    
    Examples:
        ç«å±±æ–¹èˆŸ: base_url="https://ark.cn-beijing.volces.com/api/v3"
        DeepSeek: base_url="https://api.deepseek.com"
        Moonshot: base_url="https://api.moonshot.cn/v1"
        OpenAI:   base_url=None (uses default)
    """
    model: str = "gpt-4o-mini"  # Default model; set to your endpoint ID for ç«å±±æ–¹èˆŸ
    base_url: str = None  # Set to provider's API endpoint URL
    max_tokens: int = 1500
    temperature: float = 0.7


# ============== Prompt Templates ==============

SYSTEM_PROMPT = """You are a GMAT expert tutor who has helped thousands of students achieve 99th percentile scores. 

Your teaching style:
- Patient and encouraging, but rigorous
- Focus on building fundamental reasoning skills
- Use clear, structured explanations
- Help students recognize patterns and traps

Language: Always respond in the same language as the user's question or the language they prefer. If the question is in Chinese, respond in Chinese. If in English, respond in English."""


EXPLANATION_PROMPT_TEMPLATE = """A student answered a GMAT {question_type} question. Analyze their specific mistake.

**Question Type:** {question_type}
**Question:**
{question_content}

**Options:**
A. {option_a}
B. {option_b}
C. {option_c}
D. {option_d}
E. {option_e}

**Correct Answer:** {correct_answer}
**Student Selected:** {student_answer}
**Student was correct:** {is_correct}
**Question Tags:** {skill_tags}

Please structure your explanation as follows. Adapt emphasis based on whether the student was correct or not.

## âŒ ä½ é€‰çš„ {student_answer} ä¸ºä»€ä¹ˆä¸å¯¹ï¼Ÿï¼ˆå¦‚æžœç­”å¯¹åˆ™æ”¹ä¸º"âœ… ä½ é€‰å¯¹äº†ï¼Œæ³¨æ„è¿™äº›å¹²æ‰°é¡¹"ï¼‰
This is the MOST IMPORTANT section. Be specific and detailed:
- Quote the key phrase(s) in option {student_answer} that make it wrong
- For CR: Explain the logical trap (too extreme? irrelevant comparison? necessary vs. sufficient? correlation vs. causation? out of scope?)
- For RC: Explain what the passage actually says vs. what this option distorts (over-generalization? opposite meaning? not stated? wrong detail?)
- Explain what the student was probably thinking and why that reasoning is flawed
- If the student answered correctly, briefly note the most tempting wrong answer and why it's a trap

## âœ… æ­£ç¡®ç­”æ¡ˆ {correct_answer} çš„é€»è¾‘é“¾
- In 2-3 sentences, show the direct logical connection
- For CR: premise â†’ gap â†’ how this option fills/addresses it
- For RC: passage evidence (cite specific phrases) â†’ how this option matches

## ðŸ“ å…³é”®è¯æ±‡
List 3-5 KEY English words/phrases from the question and options that are critical for understanding this question. Focus on:
- Words that change the logical direction (e.g. "nevertheless", "notwithstanding", "ostensibly")
- GMAT-specific formal vocabulary that Chinese students often misread
- Phrases that create the trap in wrong answers (e.g. "some" vs "all", "correlation" vs "causation")

Format each as:
**English word/phrase** â€” ä¸­æ–‡é‡Šä¹‰ â€” åœ¨æœ¬é¢˜ä¸­çš„ä½œç”¨ï¼ˆä¸€å¥è¯ï¼‰

## ðŸ”‘ ä¸€å¥è¯è®°ä½
One actionable takeaway sentence. Format: "é‡åˆ°[é¢˜åž‹/æƒ…å¢ƒ]ï¼Œæ³¨æ„[å…·ä½“é™·é˜±]ï¼Œå…³é”®æ˜¯[æ­£ç¡®æ€è·¯]"

Keep the total response under 500 words. Be direct and specific â€” avoid generic advice. Use the student's actual wrong choice as the teaching anchor. è¯·ç”¨ä¸­æ–‡å›žç­”ï¼ˆè¯æ±‡ç¿»è¯‘éƒ¨åˆ†ä¿ç•™è‹±æ–‡åŽŸè¯ï¼‰ã€‚"""


SUMMARY_PROMPT_TEMPLATE = """Based on today's study session, provide a brief summary and recommendations.

**Session Statistics:**
- Questions attempted: {total_questions}
- Correct answers: {correct_count}
- Accuracy: {accuracy}%
- Average time per question: {avg_time} seconds

**Errors by Category:**
{error_breakdown}

**Weakest Tags:**
{weak_tags}

Please provide:
1. A brief assessment of today's performance (2-3 sentences)
2. What went well
3. Key areas needing improvement
4. Specific recommendation for tomorrow's practice

Keep it encouraging but honest. Be concise."""


QUICK_TIP_PROMPT_TEMPLATE = """For a GMAT {question_type} question testing "{skill_tag}", give ONE quick tip (2-3 sentences max) that helps identify the correct answer pattern."""


TRANSLATION_PROMPT_TEMPLATE = """è¯·ç¿»è¯‘ä»¥ä¸‹ GMAT é¢˜ç›®ï¼Œå¹¶æ ‡æ³¨é‡ç‚¹è¯æ±‡ã€‚

**é¢˜å¹²ï¼š**
{question_content}

**é€‰é¡¹ï¼š**
A. {option_a}
B. {option_b}
C. {option_c}
D. {option_d}
E. {option_e}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

## ðŸ“– é¢˜ç›®ç¿»è¯‘

[é¢˜å¹²çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¿æŒåŽŸæ–‡é€»è¾‘ç»“æž„æ¸…æ™°]

## ðŸ”¤ é€‰é¡¹ç¿»è¯‘

A. [é€‰é¡¹Aç¿»è¯‘]
B. [é€‰é¡¹Bç¿»è¯‘]
C. [é€‰é¡¹Cç¿»è¯‘]
D. [é€‰é¡¹Dç¿»è¯‘]
E. [é€‰é¡¹Eç¿»è¯‘]

## ðŸ“š é‡ç‚¹è¯æ±‡

åˆ—å‡º 5-8 ä¸ªå¯¹ç†è§£æœ¬é¢˜æœ€å…³é”®çš„è¯æ±‡/çŸ­è¯­ï¼Œæ ¼å¼ï¼š
- **è‹±æ–‡è¯æ±‡** â€” ä¸­æ–‡é‡Šä¹‰ â€” åœ¨æœ¬é¢˜ä¸­çš„å…³é”®ä½œç”¨ï¼ˆä¸€å¥è¯ï¼‰

é‡ç‚¹å…³æ³¨ï¼š
1. æ”¹å˜é€»è¾‘æ–¹å‘çš„è¿žæŽ¥è¯ï¼ˆhowever, nevertheless, although ç­‰ï¼‰
2. ç¨‹åº¦/èŒƒå›´é™å®šè¯ï¼ˆsome, all, most, only ç­‰ï¼‰
3. å­¦æœ¯/å•†ä¸šé¢†åŸŸä¸“ä¸šè¯æ±‡
4. å®¹æ˜“è¯¯è§£çš„ç†Ÿè¯åƒ»ä¹‰"""


# ============== AI Tutor ==============

class AITutor:
    """AI-powered tutor using LLM for explanations."""
    
    def __init__(self, config: TutorConfig = None, api_key: str = None, base_url: str = None):
        self.config = config or TutorConfig()
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY") or os.environ.get("ARK_API_KEY")
        # Allow base_url from parameter, config, or env
        self.base_url = base_url or self.config.base_url or os.environ.get("OPENAI_BASE_URL")
        self._client = None
    
    def _get_client(self):
        """Lazy initialization of OpenAI-compatible client."""
        if self._client is None:
            if not self.api_key:
                return None
            try:
                from openai import OpenAI
                kwargs = {"api_key": self.api_key}
                if self.base_url:
                    kwargs["base_url"] = self.base_url
                self._client = OpenAI(**kwargs)
            except ImportError:
                print("Warning: openai package not installed. AI features disabled.")
                return None
        return self._client
    
    def is_available(self) -> bool:
        """Check if AI features are available."""
        return self._get_client() is not None
    
    def explain_failure(self, 
                       question: Question, 
                       user_answer: int,
                       is_correct: bool = False,
                       language: str = "zh") -> str:
        """
        Generate a detailed explanation focusing on why the user's choice was wrong.
        
        Args:
            question: The question object
            user_answer: Index of the user's selected answer (0-4)
            is_correct: Whether the user answered correctly
            language: "zh" for Chinese, "en" for English
        
        Returns:
            Explanation text
        """
        client = self._get_client()
        
        # Format the prompt
        option_letters = ['A', 'B', 'C', 'D', 'E']
        question_type = "Reading Comprehension (RC)" if question.subcategory == "RC" else "Critical Reasoning (CR)"
        prompt = EXPLANATION_PROMPT_TEMPLATE.format(
            question_type=question_type,
            question_content=question.content,
            option_a=question.options[0],
            option_b=question.options[1],
            option_c=question.options[2],
            option_d=question.options[3],
            option_e=question.options[4],
            correct_answer=option_letters[question.correct_answer],
            student_answer=option_letters[user_answer],
            is_correct="Yes" if is_correct else "No",
            skill_tags=", ".join(question.skill_tags)
        )
        
        if not client:
            # Fallback to stored explanation if available
            return self._fallback_explanation(question, user_answer)
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.config.max_tokens,
                temperature=self.config.temperature
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"AI explanation error: {e}")
            return self._fallback_explanation(question, user_answer)
    
    def _fallback_explanation(self, question: Question, user_answer: int) -> str:
        """Provide a structured explanation when AI is not available.

        Note: This does NOT include question.explanation to avoid duplication
        with the OGè§£æž section shown separately in the UI.
        """
        option_letters = ['A', 'B', 'C', 'D', 'E']
        correct_letter = option_letters[question.correct_answer]
        user_letter = option_letters[user_answer]
        is_correct = (user_answer == question.correct_answer)

        # Get skill-specific tips
        skill_tips = {
            "Assumption": "æ‰¾å‡è®¾é¢˜çš„å…³é”®ï¼šæ­£ç¡®ç­”æ¡ˆæ˜¯è®ºè¯æˆç«‹çš„å¿…è¦æ¡ä»¶ã€‚ç”¨'å¦å®šæµ‹è¯•'â€”â€”å¦å®šé€‰é¡¹åŽçœ‹è®ºè¯æ˜¯å¦å´©å¡Œã€‚",
            "Strengthen": "åŠ å¼ºé¢˜è¦æ‰¾èƒ½å¡«è¡¥è®ºè¯ç¼ºå£çš„é€‰é¡¹ï¼Œè®©ç»“è®º'æ›´å¯èƒ½'æˆç«‹ã€‚",
            "Weaken": "å‰Šå¼±é¢˜è¦æ”»å‡»'å‰æåˆ°ç»“è®º'çš„æŽ¨ç†è¿‡ç¨‹ï¼Œå¯»æ‰¾æ›¿ä»£è§£é‡Šæˆ–ç ´åå› æžœé“¾ã€‚",
            "Inference": "æŽ¨æ–­é¢˜è¦æ±‚'å¿…ç„¶ä¸ºçœŸ'ã€‚æ³¨æ„'å¤§å¤šæ•°'â‰ 'æ‰€æœ‰'ï¼Œæ­£ç¡®é€‰é¡¹é€šå¸¸æ›´ä¿å®ˆã€‚",
            "Evaluate": "è¯„ä¼°é¢˜è¦æ‰¾èƒ½å†³å®šè®ºè¯å¼ºå¼±çš„å…³é”®ä¿¡æ¯ã€‚",
            "Boldface": "ç²—ä½“é¢˜å…ˆåˆ¤æ–­æ¯ä¸ªç²—ä½“éƒ¨åˆ†çš„è§’è‰²ï¼Œå†çœ‹é€»è¾‘å…³ç³»ã€‚",
            "Resolve/Explain": "è§£é‡Šé¢˜è¦æ‰¾èƒ½åŒæ—¶è§£é‡Šçœ‹ä¼¼çŸ›ç›¾çš„ä¸¤ä¸ªçŽ°è±¡çš„é€‰é¡¹ã€‚",
        }

        primary_tag = question.skill_tags[0] if question.skill_tags else "General"
        tip = skill_tips.get(primary_tag, "ä»”ç»†åˆ†æžè®ºè¯ç»“æž„ï¼Œæ³¨æ„å‰æä¸Žç»“è®ºä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚")

        if is_correct:
            explanation = f"""## âœ… ç­”å¯¹äº†ï¼

**æ­£ç¡®ç­”æ¡ˆï¼š** {correct_letter}

### ðŸ“ è€ƒç‚¹æç¤º
**{primary_tag}** â€” {tip}

### ðŸ”‘ å·©å›ºè¦ç‚¹
- è€ƒç‚¹æ ‡ç­¾ï¼š{', '.join(question.skill_tags)}
- éš¾åº¦ï¼š{'â­' * question.difficulty}

_æç¤ºï¼šé…ç½® API Key åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„ AI è®²è§£ï¼ŒåŒ…æ‹¬å¹²æ‰°é¡¹åˆ†æžã€‚_"""
        else:
            explanation = f"""## âŒ ç­”æ¡ˆåˆ†æž

**æ­£ç¡®ç­”æ¡ˆï¼š** {correct_letter}
**ä½ çš„é€‰æ‹©ï¼š** {user_letter}

### ðŸ“ è€ƒç‚¹æç¤º
**{primary_tag}** â€” {tip}

### ðŸ” è‡ªæˆ‘æ£€æŸ¥æ¸…å•
1. æ˜¯å¦å‡†ç¡®ç†è§£äº†é¢˜å¹²çš„è®ºè¯ç»“æž„ï¼Ÿ
2. é€‰é¡¹ {user_letter} æ˜¯å¦å­˜åœ¨èŒƒå›´è¿‡å¤§/è¿‡å°çš„é—®é¢˜ï¼Ÿ
3. é€‰é¡¹ {user_letter} æ˜¯å¦ä¸ŽåŽŸæ–‡æ— å…³æˆ–å·æ¢æ¦‚å¿µï¼Ÿ
4. æ­£ç¡®ç­”æ¡ˆ {correct_letter} å¦‚ä½•ç›´æŽ¥æ”¯æŒ/åé©³è®ºè¯ï¼Ÿ

### ðŸ”‘ æ”¹è¿›å»ºè®®
- è€ƒç‚¹æ ‡ç­¾ï¼š{', '.join(question.skill_tags)}
- éš¾åº¦ï¼š{'â­' * question.difficulty}

_æç¤ºï¼šé…ç½® API Key åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„ AI è®²è§£ã€‚_"""

        return explanation
    
    def generate_session_summary(self,
                                logs: List[StudyLog],
                                questions: Dict[int, Question]) -> str:
        """
        Generate a summary of a study session.
        
        Args:
            logs: List of study logs from the session
            questions: Dict mapping question_id to Question objects
        """
        if not logs:
            return "æ²¡æœ‰å­¦ä¹ è®°å½•å¯ä¾›æ€»ç»“ã€‚"
        
        # Calculate statistics
        total = len(logs)
        correct = sum(1 for log in logs if log.is_correct)
        accuracy = (correct / total * 100) if total > 0 else 0
        avg_time = sum(log.time_taken for log in logs) / total if total > 0 else 0
        
        # Error breakdown
        error_counts = {}
        tag_errors = {}
        
        for log in logs:
            if not log.is_correct:
                # Count by error category
                cat = log.error_category or "Unspecified"
                error_counts[cat] = error_counts.get(cat, 0) + 1
                
                # Count by skill tag
                q = questions.get(log.question_id)
                if q:
                    for tag in q.skill_tags:
                        tag_errors[tag] = tag_errors.get(tag, 0) + 1
        
        error_breakdown = "\n".join(f"- {cat}: {count}" for cat, count in error_counts.items()) or "- None"
        
        weak_tags = sorted(tag_errors.items(), key=lambda x: x[1], reverse=True)[:3]
        weak_tags_str = "\n".join(f"- {tag}: {count} errors" for tag, count in weak_tags) or "- None"
        
        prompt = SUMMARY_PROMPT_TEMPLATE.format(
            total_questions=total,
            correct_count=correct,
            accuracy=f"{accuracy:.1f}",
            avg_time=f"{avg_time:.0f}",
            error_breakdown=error_breakdown,
            weak_tags=weak_tags_str
        )
        
        client = self._get_client()
        if not client:
            return self._fallback_summary(total, correct, accuracy, avg_time, weak_tags)
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"AI summary error: {e}")
            return self._fallback_summary(total, correct, accuracy, avg_time, weak_tags)
    
    def _fallback_summary(self, total: int, correct: int, accuracy: float, 
                         avg_time: float, weak_tags: List[tuple]) -> str:
        """Generate a basic summary when AI is not available."""
        summary = f"""## ä»Šæ—¥å­¦ä¹ æ€»ç»“

**ç»ƒä¹ æ•°æ®ï¼š**
- å®Œæˆé¢˜ç›®ï¼š{total} é¢˜
- æ­£ç¡®æ•°é‡ï¼š{correct} é¢˜
- æ­£ç¡®çŽ‡ï¼š{accuracy:.1f}%
- å¹³å‡ç”¨æ—¶ï¼š{avg_time:.0f} ç§’/é¢˜

"""
        if weak_tags:
            summary += "**è–„å¼±çŽ¯èŠ‚ï¼š**\n"
            for tag, count in weak_tags:
                summary += f"- {tag}: {count} é“é¢˜åšé”™\n"
            summary += "\n"
        
        if accuracy >= 80:
            summary += "âœ… **æ•´ä½“è¡¨çŽ°è‰¯å¥½ï¼** ç»§ç»­ä¿æŒå½“å‰çš„å­¦ä¹ èŠ‚å¥ã€‚\n"
        elif accuracy >= 60:
            summary += "ðŸ“ˆ **è¡¨çŽ°ä¸­ç­‰ã€‚** å»ºè®®é’ˆå¯¹è–„å¼±çŽ¯èŠ‚è¿›è¡Œä¸“é¡¹è®­ç»ƒã€‚\n"
        else:
            summary += "âš ï¸ **éœ€è¦åŠ å¼ºåŸºç¡€ã€‚** å»ºè®®æ”¾æ…¢é€Ÿåº¦ï¼Œä»”ç»†åˆ†æžæ¯é“é”™é¢˜ã€‚\n"
        
        summary += "\n_æç¤ºï¼šé…ç½® API Key åŽå¯èŽ·å¾—æ›´è¯¦ç»†çš„ AI åˆ†æžå’Œä¸ªæ€§åŒ–å»ºè®®ã€‚_"
        
        return summary
    
    def get_quick_tip(self, question_type: str, skill_tag: str) -> str:
        """Get a quick tip for a specific question type and skill."""
        client = self._get_client()
        
        prompt = QUICK_TIP_PROMPT_TEMPLATE.format(
            question_type=question_type,
            skill_tag=skill_tag
        )
        
        if not client:
            return self._get_fallback_tip(skill_tag)
        
        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return self._get_fallback_tip(skill_tag)
    
    def _get_fallback_tip(self, skill_tag: str) -> str:
        """Provide a static tip based on skill tag."""
        tips = {
            "Assumption": "æ‰¾å‡è®¾é¢˜çš„å…³é”®ï¼šæ­£ç¡®ç­”æ¡ˆæ˜¯è®ºè¯æˆç«‹çš„å¿…è¦æ¡ä»¶ã€‚ç”¨'å¦å®šæµ‹è¯•'â€”â€”å¦‚æžœå¦å®šæŸä¸ªé€‰é¡¹åŽè®ºè¯å´©å¡Œï¼Œé‚£å°±æ˜¯æ­£ç¡®ç­”æ¡ˆã€‚",
            "Strengthen": "åŠ å¼ºé¢˜è¦æ‰¾èƒ½å¡«è¡¥è®ºè¯ç¼ºå£çš„é€‰é¡¹ã€‚æ³¨æ„ï¼šå¥½çš„åŠ å¼ºé€‰é¡¹ä¸éœ€è¦'è¯æ˜Ž'ç»“è®ºï¼Œåªéœ€è¦è®©ç»“è®º'æ›´å¯èƒ½'æˆç«‹ã€‚",
            "Weaken": "å‰Šå¼±é¢˜è¦æ”»å‡»'å‰æåˆ°ç»“è®º'çš„æŽ¨ç†è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯æ”»å‡»å‰ææœ¬èº«ã€‚å¯»æ‰¾æ›¿ä»£è§£é‡Šæˆ–ç ´åå› æžœé“¾çš„é€‰é¡¹ã€‚",
            "Inference": "æŽ¨æ–­é¢˜è¦æ±‚'å¿…ç„¶ä¸ºçœŸ'ã€‚å°å¿ƒ'å¤§å¤šæ•°'â‰ 'æ‰€æœ‰'ï¼Œ'æœ‰äº›'â‰ 'å¿…ç„¶'ã€‚æ­£ç¡®é€‰é¡¹é€šå¸¸æ¯”ä½ é¢„æœŸçš„æ›´ä¿å®ˆã€‚",
            "Evaluate": "è¯„ä¼°é¢˜è¦æ‰¾èƒ½å†³å®šè®ºè¯å¼ºå¼±çš„å…³é”®ä¿¡æ¯ã€‚é—®è‡ªå·±ï¼š'å¦‚æžœçŸ¥é“è¿™ä¸ªä¿¡æ¯ï¼Œç»“è®ºä¼šæ›´å¼ºè¿˜æ˜¯æ›´å¼±ï¼Ÿ'",
            "Boldface": "ç²—ä½“é¢˜å…ˆåˆ¤æ–­æ¯ä¸ªç²—ä½“éƒ¨åˆ†çš„è§’è‰²ï¼ˆç»“è®ºï¼Ÿå‰æï¼Ÿåé©³ï¼Ÿï¼‰ï¼Œå†çœ‹å®ƒä»¬ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚"
        }
        return tips.get(skill_tag, "ä»”ç»†é˜…è¯»é¢˜å¹²ï¼Œè¯†åˆ«è®ºè¯ç»“æž„ï¼Œæ³¨æ„é¢˜ç›®é—®çš„æ˜¯ä»€ä¹ˆã€‚")

    def translate_question(self, question: Question) -> str:
        """
        Translate question and options to Chinese with key vocabulary highlighted.

        Args:
            question: The question object

        Returns:
            Translated content with vocabulary notes
        """
        client = self._get_client()

        prompt = TRANSLATION_PROMPT_TEMPLATE.format(
            question_content=question.content,
            option_a=question.options[0],
            option_b=question.options[1],
            option_c=question.options[2],
            option_d=question.options[3],
            option_e=question.options[4],
        )

        if not client:
            return self._fallback_translation(question)

        try:
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ GMAT ç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å‡†ç¡®ç¿»è¯‘å•†ä¸šå’Œé€»è¾‘æŽ¨ç†ç±»æ–‡æœ¬ï¼ŒåŒæ—¶æ ‡æ³¨å…³é”®è¯æ±‡å¸®åŠ©å­¦ç”Ÿç†è§£ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.3  # Lower temperature for more accurate translation
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Translation error: {e}")
            return self._fallback_translation(question)

    def _fallback_translation(self, question: Question) -> str:
        """Provide basic translation guidance when AI is not available."""
        option_letters = ['A', 'B', 'C', 'D', 'E']

        # Common GMAT vocabulary
        common_vocab = {
            "however": "ç„¶è€Œï¼Œä½†æ˜¯ï¼ˆè½¬æŠ˜ï¼‰",
            "nevertheless": "å°½ç®¡å¦‚æ­¤ï¼Œç„¶è€Œ",
            "although": "è™½ç„¶ï¼Œå°½ç®¡",
            "therefore": "å› æ­¤ï¼Œæ‰€ä»¥",
            "thus": "å› æ­¤ï¼Œè¿™æ ·",
            "moreover": "æ­¤å¤–ï¼Œè€Œä¸”",
            "furthermore": "æ­¤å¤–ï¼Œå†è€…",
            "consequently": "å› æ­¤ï¼Œç»“æžœ",
            "assumption": "å‡è®¾ï¼Œå‰æ",
            "conclusion": "ç»“è®º",
            "premise": "å‰æ",
            "evidence": "è¯æ®",
            "imply": "æš—ç¤ºï¼Œæ„å‘³ç€",
            "infer": "æŽ¨æ–­ï¼ŒæŽ¨è®º",
            "suggest": "è¡¨æ˜Žï¼Œæš—ç¤º",
            "indicate": "è¡¨æ˜Žï¼ŒæŒ‡å‡º",
            "argue": "è®ºè¯ï¼Œä¸»å¼ ",
            "claim": "å£°ç§°ï¼Œä¸»å¼ ",
            "assert": "æ–­è¨€ï¼Œå£°ç§°",
            "contend": "ä¸»å¼ ï¼Œäº‰è¾©",
            "maintain": "åšæŒè®¤ä¸ºï¼Œç»´æŒ",
            "substantial": "å¤§é‡çš„ï¼Œå®žè´¨çš„",
            "significant": "é‡è¦çš„ï¼Œæ˜¾è‘—çš„",
            "considerable": "ç›¸å½“å¤§çš„",
            "primarily": "ä¸»è¦åœ°",
            "exclusively": "ä¸“é—¨åœ°ï¼ŒæŽ’ä»–åœ°",
            "merely": "ä»…ä»…ï¼Œåªä¸è¿‡",
            "solely": "ä»…ä»…ï¼Œå”¯ä¸€åœ°",
        }

        # Find vocabulary that appears in the question
        question_text = question.content.lower()
        found_vocab = []
        for word, translation in common_vocab.items():
            if word in question_text:
                found_vocab.append(f"- **{word}** â€” {translation}")

        result = """## ðŸ“– ç¿»è¯‘æç¤º

_AI ç¿»è¯‘åŠŸèƒ½éœ€è¦é…ç½® API Keyã€‚é…ç½®åŽå¯èŽ·å¾—å®Œæ•´çš„é¢˜ç›®ç¿»è¯‘å’Œé‡ç‚¹è¯æ±‡åˆ†æžã€‚_

## ðŸ“š å¸¸è§ GMAT è¯æ±‡å‚è€ƒ

"""
        if found_vocab:
            result += "**æœ¬é¢˜ä¸­å‡ºçŽ°çš„å…³é”®è¯ï¼š**\n\n"
            result += "\n".join(found_vocab[:8])
        else:
            result += """**é€»è¾‘è¿žæŽ¥è¯ï¼š**
- **however** â€” ç„¶è€Œï¼ˆè½¬æŠ˜ï¼‰
- **therefore** â€” å› æ­¤ï¼ˆå› æžœï¼‰
- **although** â€” è™½ç„¶ï¼ˆè®©æ­¥ï¼‰
- **moreover** â€” æ­¤å¤–ï¼ˆé€’è¿›ï¼‰

**è®ºè¯ç›¸å…³ï¼š**
- **assumption** â€” å‡è®¾
- **conclusion** â€” ç»“è®º
- **evidence** â€” è¯æ®
- **imply** â€” æš—ç¤º"""

        result += "\n\n_é…ç½® API Key åŽå¯èŽ·å¾—æœ¬é¢˜çš„å®Œæ•´ç¿»è¯‘ã€‚_"
        return result


# ============== Error Taxonomy Reference ==============

ERROR_TAXONOMY = {
    "Understanding": {
        "description": "ç†è§£å±‚é¢çš„é”™è¯¯ - æ²¡æœ‰æ­£ç¡®ç†è§£é¢˜ç›®æˆ–é€‰é¡¹çš„å«ä¹‰",
        "types": {
            "Text Misinterpretation": "è¯¯è§£é¢˜å¹²ä¸­çš„å…³é”®ä¿¡æ¯æˆ–è®ºè¯ç»“æž„",
            "Option Misinterpretation": "è¯¯è§£é€‰é¡¹çš„å®žé™…å«ä¹‰"
        },
        "remedy": "æ”¾æ…¢é˜…è¯»é€Ÿåº¦ï¼Œç”¨è‡ªå·±çš„è¯å¤è¿°è®ºè¯"
    },
    "Reasoning": {
        "description": "æŽ¨ç†å±‚é¢çš„é”™è¯¯ - ç†è§£äº†ä½†æŽ¨ç†è¿‡ç¨‹å‡ºé”™",
        "types": {
            "Confusion (Suff/Nec)": "æ··æ·†å……åˆ†æ¡ä»¶å’Œå¿…è¦æ¡ä»¶",
            "Reverse Causality": "é¢ å€’å› æžœå…³ç³»",
            "Scope Shift": "èŒƒå›´è½¬ç§» - é€‰é¡¹è®¨è®ºçš„èŒƒå›´ä¸Žé¢˜å¹²ä¸ä¸€è‡´",
            "Trap Answer": "æŽ‰å…¥å¸¸è§é™·é˜±é€‰é¡¹"
        },
        "remedy": "ç»ƒä¹ è¯†åˆ«è®ºè¯æ¨¡å¼ï¼Œå­¦ä¹ å¸¸è§é™·é˜±ç±»åž‹"
    },
    "Execution": {
        "description": "æ‰§è¡Œå±‚é¢çš„é”™è¯¯ - ä¼šåšä½†åšé”™äº†",
        "types": {
            "Time Pressure": "æ—¶é—´åŽ‹åŠ›å¯¼è‡´ä»“ä¿ƒç­”é¢˜",
            "Careless": "ç²—å¿ƒå¤§æ„ï¼Œæ¼çœ‹å…³é”®è¯"
        },
        "remedy": "ç»ƒä¹ æ—¶é—´ç®¡ç†ï¼Œå»ºç«‹æ£€æŸ¥ä¹ æƒ¯"
    }
}


def get_error_taxonomy() -> Dict:
    """Return the error taxonomy for UI display."""
    return ERROR_TAXONOMY


def translate_question(tutor: 'AITutor', question: Question) -> str:
    """Convenience function to translate a question using the provided tutor instance."""
    return tutor.translate_question(question)


# ============== Test ==============

def test_tutor():
    """Test the AI tutor with a sample question."""
    print("\n=== Testing AI Tutor ===\n")
    
    tutor = AITutor()
    
    print(f"AI Available: {tutor.is_available()}")
    
    # Create a sample question
    sample_q = Question(
        id=1,
        passage_id=None,
        category="Verbal",
        subcategory="CR",
        content="Studies show that employees who work from home report higher job satisfaction. Therefore, all companies should mandate remote work.",
        options=[
            "Working from home is possible for all jobs",
            "Job satisfaction improves productivity",
            "Remote workers are more loyal",
            "Office rent is expensive",
            "Commuting is stressful"
        ],
        correct_answer=0,
        skill_tags=["Assumption"],
        difficulty=3,
        explanation="The argument assumes all jobs can be done remotely."
    )
    
    print("Testing explanation generation...")
    explanation = tutor.explain_failure(sample_q, user_answer=1)
    print(explanation[:500] + "..." if len(explanation) > 500 else explanation)
    
    print("\nâœ“ Tutor test complete!")


if __name__ == "__main__":
    test_tutor()
